{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Feature Engineering\n",
    "\n",
    "**Purpose**: Create derived features for modeling and deeper analysis.\n",
    "\n",
    "**Features to Create**:\n",
    "1. **Matchup features**: Trophy diff, elixir diff, card level diff\n",
    "2. **Deck complexity**: Weighted score based on elixir, spell count, legendary count\n",
    "3. **Archetype indicators**: Beatdown, cycle, spell-heavy flags\n",
    "4. **Card synergy scores**: Based on historical win rates of card pairs\n",
    "5. **Trophy brackets**: Categorical variables for skill levels\n",
    "\n",
    "**Output**: Clean feature matrix saved as Parquet for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, duckdb, pandas as pd, numpy as np\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, os.path.join(PROJECT_ROOT, 'src'))\n",
    "\n",
    "# Use Parquet if available (faster), fallback to CSV\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, 'battles.parquet')\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    DATA_PATH = os.path.join(PROJECT_ROOT, 'battles.csv')\n",
    "\n",
    "from duckdb_utils import get_connection, create_battles_view, query_to_df, save_to_parquet, create_sample\n",
    "from feature_engineering import (\n",
    "    create_card_level_features,\n",
    "    create_deck_archetype_features,\n",
    "    create_trophy_bracket_features,\n",
    "    create_matchup_features,\n",
    "    create_tower_damage_features\n",
    ")\n",
    "\n",
    "con = get_connection()\n",
    "create_battles_view(con, DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Base Data\n",
    "\n",
    "Work with a sample for feature engineering development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create 10% sample if not exists\nsample_path = 'artifacts/sample_battles_10pct.parquet'\nsample_file = os.path.join(PROJECT_ROOT, sample_path)\n\nif not os.path.exists(sample_file):\n    print(\"Creating 10% sample...\")\n    sample = create_sample(con, sample_pct=10, output_path=sample_path)\n    print(f\"✓ Sample created and saved to {sample_path}\")\nelse:\n    print(\"Loading existing sample...\")\n    sample = pd.read_parquet(sample_file)\n    print(f\"✓ Sample loaded from {sample_path}\")\n    \nprint(f\"Sample size: {len(sample):,} battles\")\nprint(f\"Columns: {len(sample.columns)}\")\nprint(f\"Memory usage: {sample.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Matchup Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Add matchup comparison features\nprint(\"Creating matchup features...\")\nsample_features = create_matchup_features(sample)\n\nprint(\"✓ Matchup features created:\")\nprint(\"  - trophy_diff: Winner trophy advantage\")\nprint(\"  - elixir_diff: Winner elixir cost advantage\")  \nprint(\"  - card_level_diff: Winner card level advantage\")\nprint(\"  - spell_diff: Winner spell count advantage\")\n\n# Show summary stats\nprint(f\"\\nSample stats:\")\nprint(f\"  Average trophy diff: {sample_features['trophy_diff'].mean():.1f}\")\nprint(f\"  Average elixir diff: {sample_features['elixir_diff'].mean():.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Deck Archetype Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Add archetype indicators for winner and loser\nprint(\"Creating archetype features...\")\nsample_features = create_deck_archetype_features(sample_features, player='winner')\nsample_features = create_deck_archetype_features(sample_features, player='loser')\n\nprint(\"✓ Archetype features created for both players:\")\n\n# List all archetype columns\narchetype_cols = [col for col in sample_features.columns if 'archetype' in col.lower() \n                  or 'beatdown' in col.lower() or 'cycle' in col.lower() \n                  or 'heavy' in col.lower() or 'siege' in col.lower()]\nfor col in sorted(archetype_cols):\n    print(f\"  - {col}\")\n\n# Show archetype distribution for winners\nwinner_archetypes = [col for col in archetype_cols if 'winner' in col]\nif len(winner_archetypes) > 0:\n    print(f\"\\nWinner archetype distribution:\")\n    for col in winner_archetypes[:5]:\n        if col in sample_features.columns:\n            pct = sample_features[col].sum() / len(sample_features) * 100\n            print(f\"  {col}: {pct:.1f}% of decks\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Trophy Bracket Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Categorize battles by trophy level\nprint(\"Creating trophy bracket features...\")\nsample_features = create_trophy_bracket_features(sample_features)\n\nprint(\"✓ Trophy bracket feature created\")\n\n# Show distribution\nif 'trophy_bracket' in sample_features.columns:\n    print(\"\\nTrophy bracket distribution:\")\n    bracket_counts = sample_features['trophy_bracket'].value_counts().sort_index()\n    for bracket, count in bracket_counts.items():\n        pct = count / len(sample_features) * 100\n        print(f\"  {bracket}: {count:,} battles ({pct:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Tower Damage Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Add crown-related features\nprint(\"Creating tower damage features...\")\nsample_features = create_tower_damage_features(sample_features)\n\nprint(\"✓ Tower damage features created:\")\nprint(\"  - crown_diff: Crown advantage\")\nprint(\"  - close_game: Boolean for 1-crown wins\")\nprint(\"  - three_crown_win: Boolean for 3-crown wins\")\n\n# Show distribution\nif 'close_game' in sample_features.columns:\n    close_pct = sample_features['close_game'].sum() / len(sample_features) * 100\n    print(f\"\\nClose games (1-crown): {close_pct:.1f}%\")\n\nif 'three_crown_win' in sample_features.columns:\n    three_crown_pct = sample_features['three_crown_win'].sum() / len(sample_features) * 100\n    print(f\"3-crown wins: {three_crown_pct:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save engineered features for modeling\noutput_path = os.path.join(PROJECT_ROOT, 'artifacts/model_features.parquet')\nprint(f\"Saving feature matrix to {output_path}...\")\n\nsave_to_parquet(sample_features, 'artifacts/model_features.parquet')\n\nprint(f\"\\n✓ Feature matrix saved!\")\nprint(f\"  Shape: {sample_features.shape}\")\nprint(f\"  File size: {os.path.getsize(output_path) / 1024**2:.1f} MB\")\nprint(f\"  Total features: {len(sample_features.columns)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# List all engineered features\nengineered_cols = [col for col in sample_features.columns \n                   if any(x in col for x in ['_diff', '_heavy', '_beatdown', '_cycle', \n                                              'bracket', 'close_game', 'archetype', 'siege',\n                                              'crown_diff', 'three_crown'])]\n\nprint(f\"✓ Engineered features ({len(engineered_cols)}):\")\nfor col in sorted(engineered_cols):\n    # Get data type and sample value\n    dtype = sample_features[col].dtype\n    sample_val = sample_features[col].iloc[0]\n    print(f\"  - {col:<30} ({dtype}, e.g., {sample_val})\")\n\nprint(f\"\\n✓ Feature engineering complete!\")\nprint(f\"  Ready for modeling in Notebook 06\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}