{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Modeling: Battle Outcome Prediction\n",
    "\n",
    "**Purpose**: Build predictive models for technical rigor scoring.\n",
    "\n",
    "**Goal**: Predict battle outcomes based on deck composition alone.\n",
    "\n",
    "**Benchmark**: Previous research achieved **56.94% accuracy** - aim to beat this!\n",
    "\n",
    "**Models to Try**:\n",
    "1. Logistic Regression (baseline)\n",
    "2. Random Forest (feature importance insights)\n",
    "3. XGBoost (likely best performance)\n",
    "\n",
    "**Key Metrics**:\n",
    "- Accuracy\n",
    "- Precision/Recall\n",
    "- ROC-AUC\n",
    "- Feature importance (for insights!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, os.path.join(PROJECT_ROOT, 'src'))\n",
    "\n",
    "from visualization import setup_presentation_style\n",
    "setup_presentation_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load engineered features from notebook 05\n",
    "features = pd.read_parquet(os.path.join(PROJECT_ROOT, 'artifacts/model_features.parquet'))\n",
    "\n",
    "print(f\"Loaded {len(features):,} battles with {len(features.columns)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define target variable (1 = winner won, 0 = loser won - always 1 in this dataset!)\n",
    "# Need to restructure: each battle becomes 2 rows (one for each player)\n",
    "# with outcome = 1 if that player won, 0 if lost\n",
    "\n",
    "# Example structure:\n",
    "# y = features['outcome']  # 1 or 0\n",
    "# X = features[feature_columns]  # numeric features only\n",
    "\n",
    "print(\"TODO: Restructure data and select features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "print(\"TODO: Create train/test split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 1: Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train logistic regression\n",
    "# lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# lr_model.fit(X_train, y_train)\n",
    "# lr_pred = lr_model.predict(X_test)\n",
    "# lr_acc = accuracy_score(y_test, lr_pred)\n",
    "# print(f\"Logistic Regression Accuracy: {lr_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train random forest\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# rf_pred = rf_model.predict(X_test)\n",
    "# rf_acc = accuracy_score(y_test, rf_pred)\n",
    "# print(f\"Random Forest Accuracy: {rf_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train XGBoost\n",
    "# xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "# xgb_pred = xgb_model.predict(X_test)\n",
    "# xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "# print(f\"XGBoost Accuracy: {xgb_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "**THIS IS KEY FOR PRESENTATION INSIGHTS!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract feature importances from best model\n",
    "# Plot top 15 most important features\n",
    "# These tell the story of what matters most for winning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create summary table\n",
    "# results = pd.DataFrame({\n",
    "#     'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "#     'Accuracy': [lr_acc, rf_acc, xgb_acc],\n",
    "#     'ROC-AUC': [...]\n",
    "# })\n",
    "\n",
    "print(\"TODO: Summarize model performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights for Presentation\n",
    "\n",
    "**Key Points**:\n",
    "1. Achieved X% accuracy (compare to 56.94% benchmark)\n",
    "2. Top 3 most important features are: [list]\n",
    "3. This means: [actionable insight from feature importance]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
